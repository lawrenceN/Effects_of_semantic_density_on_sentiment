{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U4-M8-Creating_the_initial_K-Means_clusters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lawrenceN/Effects_of_semantic_density_on_sentiment/blob/master/U4_M8_Creating_the_initial_K_Means_clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UUyAlh-eUqD3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "OK, let's get to our example.  We have an array of centroids, or proposed centers for our clusters, and we have a group of points that we want to assign to those centroids. To do that, we're going to look at each point and find the distance to each centroid, then assign it to the closest one.\n",
        "\n",
        "The first thing we need to do is expand the points and the centroids arrays so we can make the math work:"
      ]
    },
    {
      "metadata": {
        "id": "8DkleICBUqD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "        centroids_plot.set_data(\n",
        "           centroids[:, 0], \n",
        "           centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylAmQnzbUqEA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All right let's talk about what we're going to do with these things.  To assign each point to the closest centroid, we're going to find the distance between each point and each centroid, and assign the point to the centroid for which the distance is the smallest.\n",
        "\n",
        "Now, remember back when we were talking about scalars and vectors, and how a vector has magnitude, or length, and also direction?  Well, we need to take that into consideration when we are trying to find the distance between two points.  \n",
        "\n",
        "We'll start out by finding the displacement, which is basically the vector that goes from the tail of one to the head of the other, like this:\n",
        "\n",
        "![image](https://s3-us-west-2.amazonaws.com/livevideo-collab-resources/Machine+learning+for+mere+mortals/figure4_8_1.png)\n",
        "\n",
        "Fortunately, TensorFlow can easily do all of this with the subtract function:"
      ]
    },
    {
      "metadata": {
        "id": "hjG-jfozUqEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        print(session.run(displacement))\n",
        "\n",
        "        centroids_plot.set_data(\n",
        "           centroids[:, 0], \n",
        "           centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOHtV_jfUqEG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we're subtracting one set of tensors from another set of tensors, we'll wind up with a third set of tensors, as you can see. So each of those pairs represents the displacement, that is, the vector between the point and the centroid.  So the next thing we need to do is find the smallest vector for each point, because that's the closest centroid.  Remember...\n",
        "\n",
        "![triangle_graphic](https://s3-us-west-2.amazonaws.com/livevideo-collab-resources/Machine+learning+for+mere+mortals/figure4_8_2.png)\n",
        "\n",
        "`c**2 = a**2 + b**2`\n",
        "\n",
        "So we could do the math to find the length of each of those 600 vectors, but we don't actually need to go that far. Instead of finding \n",
        "\n",
        "`min(sqrt(a**2 + b**2))`\n",
        "\n",
        "We can just find\n",
        "\n",
        "`min(a**2 + b**2)`\n",
        "\n",
        "Because that's going to be the same, and it's going to save us 600 square root operations.  So let's go ahead and do that."
      ]
    },
    {
      "metadata": {
        "id": "MidlN5kaUqEG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import animation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "print(points_values)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "        print(session.run(distances))\n",
        "\n",
        "        centroids_plot.set_data(\n",
        "               centroids[:, 0], \n",
        "               centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdNvRDunUqEL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So first we're squaring the values in the displacement matrix, which gives us\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E3bnqilgebAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "`[a**2, b**2]`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BA1UI37aek6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But then we need to add them up, and the way that we do that is with the reduce_sum() function.  What that does is it adds up the values on the specified dimension.  Here's what I mean by that. Say we have this tensor:"
      ]
    },
    {
      "metadata": {
        "id": "HsZY55wIUqEM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = tf.constant([[[1,1,1], [1,1,1], [1,1,1], [1,1,1]], [[2,2,2], [2,2,2], [2,2,2], [2,2,2]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnpS1PHlerlF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we use tf.reduce_sum() without specifying a dimension, we wind up adding up all of the values for a single scalar:"
      ]
    },
    {
      "metadata": {
        "id": "KnYWkreZUqES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.reduce_sum(start))\n",
        "print(session.run(tf.reduce_sum(start)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXXlQDBmUqEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we use `tf.reduce_sum(start, 0)` to add up the 0th level of groups, we have"
      ]
    },
    {
      "metadata": {
        "id": "lM-3TiwSUqEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.reduce_sum(start, 0))\n",
        "print(session.run(tf.reduce_sum(start, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7zYghNxUqEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Meanwhile, `reduce_sum(start, 1)` adds up the second level of groups, so "
      ]
    },
    {
      "metadata": {
        "id": "dTI6yOD-UqEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.reduce_sum(start, 1))\n",
        "print(session.run(tf.reduce_sum(start, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQsFIAqViXec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "reduce_sum(start, 2) adds up the third level..."
      ]
    },
    {
      "metadata": {
        "id": "Cer_grzYUqEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.reduce_sum(start, 2))\n",
        "print(session.run(tf.reduce_sum(start, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_wzDThnUqEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "... and so on.\n",
        "\n",
        "In the case of our distances, it's that third level that we want.  The shape starts as\n",
        "\n",
        "`[3, 600, 2]`\n",
        "\n",
        "and we're trying to get to \n",
        "\n",
        "`[3, 600]`\n",
        "\n",
        "because that gives us the distance between each centroid and each point. So it's that 2, in the third position, that we want to reduce, so we're using\n",
        "\n",
        "`distances = tf.reduce_sum(squared_displacement, 2)`\n",
        "\n",
        "The next step is to assign each point to the centroid for which the distance is the smallest.  We'll do that using the `argmin()` function. The `argmin()` function sounds kind of weird, but what it's doing is giving you the index, or argument, of the smallest item in the specified axis, which in this case is the zeroth axis.\n",
        "\n",
        "We start out with three distances for each point, and for each point, argmin returns the index of the lowest distance.  So when we run it, we wind up with an array of assignments."
      ]
    },
    {
      "metadata": {
        "id": "qr7B0TyjUqEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "\n",
        "        assignments = tf.argmin(distances, 0) \n",
        "        assignment_values = session.run(assignments)\n",
        "        print(assignment_values)\n",
        "        \n",
        "        centroids_plot.set_data(\n",
        "               centroids[:, 0], \n",
        "               centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cENPwPYxUqEw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So we're almost there with the math.  Now we need to create three partitions, or groups -- one for each centroid -- and assign each point to the one that corresponds to that minimum."
      ]
    },
    {
      "metadata": {
        "id": "79gr7XKRUqEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "\n",
        "        assignments = tf.argmin(distances, 0)\n",
        "        assignment_values = session.run(assignments)\n",
        "\n",
        "        partitions = tf.dynamic_partition(points,       \n",
        "                                     tf.to_int32(assignment_values), \n",
        "                                     num_clusters)\n",
        "        print(session.run(partitions))\n",
        "\n",
        "        centroids_plot.set_data(\n",
        "               centroids[:, 0], \n",
        "               centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yQJf6rDUqE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `dynamic_partition()` function takes the set of points, or the data, and the assignments, as well as the number of partitions that we have, and creates those groupings for us.\n",
        "\n",
        "Once we have that, we can go ahead and determine what the new centroids are by finding the average position of each grouping."
      ]
    },
    {
      "metadata": {
        "id": "JkggLXJtUqE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "print(points_values)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "        \n",
        "        assignments = tf.argmin(distances, 0)\n",
        "        assignment_values = session.run(assignments)\n",
        "\n",
        "        partitions = tf.dynamic_partition(points,       \n",
        "                                      tf.to_int32(assignment_values), \n",
        "                                      num_clusters)\n",
        "\n",
        "        newcentroids = np.zeros((num_clusters, 2))\n",
        "        for i in range(num_clusters):\n",
        "            newcentroids[i] = session.run(tf.reduce_mean(partitions[i], 0))\n",
        "            \n",
        "        centroids_plot.set_data(\n",
        "               centroids[:, 0], \n",
        "               centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2a6MqlHZUqE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we'll create a new array called `newcentroids` to hold the `x` and `y` coordinates of each cluster.  Then for each cluster, we'll get the mean, or the average, of the `x` and `y` values for all the points in the cluster.\n",
        "\n",
        "So as you can see here, we have new values for the centroids.\n",
        "\n",
        "Now the key here is that as long as the centroids are moving, it means that the algorithm is still working on finding the optimal position for them. Once we get there, we can stop, so before we move on we'll see if we're ready.\n",
        "\n",
        "First we're comparing the old centroid array with the new array. If they're equal, then the centroids haven't moved, because none of the points have switched centroids.  So our results aren't going to get any better, and we can stop trying.  So we'll set `not_finished` to `False` and output the number of steps it took and the centroids.\n",
        "\n",
        "On other hand, if they're not equal, that means that we're still working on getting a better result, so we'll set the values of the `centroids` object to the new values, then expand the dimensions the way we did before so we're ready to start a new iteration.\n",
        "\n",
        "Now we can run this right now, and we'll see the centroids move:"
      ]
    },
    {
      "metadata": {
        "id": "9buLMXs-UqE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "field_size = 10\n",
        "not_finished = True\n",
        "\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "\n",
        "centroids = field_size * centroids\n",
        "fig = plt.figure()\n",
        "\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "        assignments = tf.argmin(distances, 0)\n",
        "        \n",
        "        assignment_values = session.run(assignments)\n",
        "        partitions = tf.dynamic_partition(points,       \n",
        "                                      tf.to_int32(assignment_values), \n",
        "                                      num_clusters)\n",
        "\n",
        "        newcentroids = np.zeros((num_clusters, 2))\n",
        "        for i in range(num_clusters):\n",
        "            newcentroids[i] = session.run(tf.reduce_mean(partitions[i], 0))\n",
        "\n",
        "        if (np.array_equal(centroids, newcentroids)):\n",
        "            not_finished = False\n",
        "            print(\"Finished after \"+str(this_iteration)+\" steps.\")\n",
        "            print(centroids)\n",
        "        else:\n",
        "            centroids = newcentroids\n",
        "            centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "        centroids_plot.set_data(\n",
        "               centroids[:, 0], \n",
        "               centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, \n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=100)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-4EtQkBhUqE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There you can see that it stops after some number of steps, because it's not getting any better.\n",
        "\n",
        "(Note that we specified `frames=200`, which means that the animation will iterate through the integers 0 through 200, then stop, even if we don't find the solution.)\n",
        "\n",
        "The problem here, though, is that we still don't know which points belong to which cluster.  So let's take care of that next. \n",
        "\n",
        "First we need to define an object to hold the points to be plotted.  We'll do that the same way we created one to hold the centroids to plot:"
      ]
    },
    {
      "metadata": {
        "id": "CGam3KPJUqFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "points_plot = {}\n",
        "points_plot[0], = graph.plot([], [], 'r.')\n",
        "points_plot[1], = graph.plot([], [], 'b.')\n",
        "points_plot[2], = graph.plot([], [], 'g.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqHLp7XGUqFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So we're creating the points_plot object.  What we want is for each cluster of points to have its own color, so we've got an array of points_plot objects, each of which, like the centroids_plot object, creates an empty data set and defines what it should look like. \n",
        "\n",
        "So the first group is going to be red dots, the second will be blue dots, and the third will be green dots.  Now, I'm going to confess that I'm taking a little shortcut here, and directly defining three sets because I know that we have 3, but if this were a real application I'd be defining arrays of colors, then just creating the number of clusters that we have, and so on, but I'll leave that as an exercise for the reader, as they say.\n",
        "\n",
        "OK, now let's put them to use.\n",
        "\n",
        "So if we're still working on getting better results, we'll start by clearing out the three groups of points to plot.  Then for each point, our goal is to assign the `x` and `y` coordinate to the proper `points_plot` grouping.\n",
        "\n",
        "So we'll start out by getting a reference to the right grouping.  Remember, `assignment_values` is a list of cluster numbers, with one corresponding to each point.  Also, these are tuples, so don't forget the comma after both sides.\n",
        "\n",
        "Next we're going to get all of the existing `x` values for that cluster, and we're going to append the `x` value for the current point to it.  We'll do the same thing for the `y` data.  Then we'll set the data for the cluster to be the new sets of `x` and `y` data.\n",
        "\n",
        "Finally, we'll add the three sets of points to plot to the output of the function so that when the animation runs (you remember the animation, right? This is a discussion about the animation) the points will get plotted too.\n",
        "\n",
        "So let's run it."
      ]
    },
    {
      "metadata": {
        "id": "_hqUkRsKUqFD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "from matplotlib import animation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_points = 600\n",
        "num_clusters = 3\n",
        "num_iterations = 100\n",
        "field_size = 10\n",
        "\n",
        "not_finished = True\n",
        "centroids = np.random.random_sample([num_clusters, 2])\n",
        "centroids = field_size * centroids\n",
        "\n",
        "fig = plt.figure()\n",
        "graph = plt.axes(xlim=(-1*field_size, field_size), \n",
        "                 ylim=(-1*field_size, field_size))\n",
        "\n",
        "centroids_plot, = graph.plot([], [], 'kx', markersize=15, markeredgewidth=3)\n",
        "\n",
        "points_plot = {}\n",
        "points_plot[0], = graph.plot([], [], 'r.')\n",
        "points_plot[1], = graph.plot([], [], 'b.')\n",
        "points_plot[2], = graph.plot([], [], 'g.')\n",
        "\n",
        "points_build = np.random.laplace(field_size/4, field_size/4, [num_points,2])\n",
        "points = tf.constant(points_build, dtype=tf.float64)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "\n",
        "points_values = session.run(points)\n",
        "\n",
        "points_expanded = tf.expand_dims(points, 0)\n",
        "centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "def updatefigure(this_iteration):\n",
        "\n",
        "    global centroids, not_finished, num_iterations, points_expanded, centroids_expanded\n",
        "\n",
        "    if (not_finished and this_iteration < num_iterations):\n",
        "        displacement = tf.subtract(points_expanded, centroids_expanded)\n",
        "        squared_displacement = tf.square(displacement)\n",
        "        distances = tf.reduce_sum(squared_displacement, 2)\n",
        "        \n",
        "        assignments = tf.argmin(distances, 0)\n",
        "        assignment_values = session.run(assignments)\n",
        "\n",
        "        partitions = tf.dynamic_partition(points,       \n",
        "                                      tf.to_int32(assignment_values), \n",
        "                                      num_clusters)\n",
        "\n",
        "        newcentroids = np.zeros((num_clusters, 2))\n",
        "\n",
        "        for i in range(num_clusters):\n",
        "            newcentroids[i] = session.run(tf.reduce_mean(partitions[i], 0))\n",
        "\n",
        "        if (np.array_equal(centroids, newcentroids)):\n",
        "            not_finished = False\n",
        "            print(\"Finished after \"+str(this_iteration)+\" steps.\")\n",
        "            print(centroids)\n",
        "        else:\n",
        "            centroids = newcentroids\n",
        "            centroids_expanded = tf.expand_dims(centroids, 1)\n",
        "\n",
        "            points_plot[0].set_data([], [])\n",
        "            points_plot[1].set_data([], [])\n",
        "            points_plot[2].set_data([], [])\n",
        "\n",
        "            for i in range(num_points-1):\n",
        "                this_set, = points_plot[assignment_values[i]],\n",
        "                xdata = this_set.get_data()[0]\n",
        "                xdata = np.append(xdata, points_values[i][0])\n",
        "                ydata = this_set.get_data()[1]\n",
        "                ydata = np.append(ydata, points_values[i][1])\n",
        "                this_set.set_data(xdata, ydata)\n",
        "\n",
        "            centroids_plot.set_data(\n",
        "                            centroids[:, 0], \n",
        "                            centroids[:, 1])\n",
        "\n",
        "    return centroids_plot, points_plot[0], points_plot[1], points_plot[2],\n",
        "\n",
        "anim = animation.FuncAnimation(fig=fig, func=updatefigure, frames=200, interval=500)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QoojJVSdUqFH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "OK!  Now we're getting somewhere!  We got TensorFlow to do k-means clustering for us, and we can see the results.\n",
        "\n",
        "Just a quick warning, here, this can get kind of hypnotic, so try not to … get … sucked … in…\n",
        "\n",
        "Right.  So next let's look at using clustering in a completely different way.  Let's look at clustering twitter topics."
      ]
    }
  ]
}